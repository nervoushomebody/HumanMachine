{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2VV0vTOmWeH",
        "outputId": "68be7d51-75cc-4679-b3af-d22827ae4388"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrN5GYWfmb3f",
        "outputId": "6a0575d1-28f5-47c4-aac0-1f178d3f3d28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgF0mQGLl-16",
        "outputId": "aef28219-523d-48e8-a018-2c3a77961a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кількість позитивних слів: 2006\n",
            "Кількість негативних слів: 4783\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import opinion_lexicon\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Завантажуємо необхідні ресурси NLTK\n",
        "nltk.download('opinion_lexicon')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # Open Multilingual Wordnet\n",
        "\n",
        "# Завантажуємо списки позитивних та негативних слів\n",
        "positive_words = set(opinion_lexicon.positive())\n",
        "negative_words = set(opinion_lexicon.negative())\n",
        "\n",
        "print(f\"Кількість позитивних слів: {len(positive_words)}\")\n",
        "print(f\"Кількість негативних слів: {len(negative_words)}\")\n",
        "\n",
        "# (Опціонально) Функція для розширення списку слів синонімами з WordNet\n",
        "def expand_with_synonyms(word_set, lang='eng'):\n",
        "    synonyms = set()\n",
        "    for word in word_set:\n",
        "        for syn in wordnet.synsets(word, lang=lang):\n",
        "            for lemma in syn.lemmas(lang=lang):\n",
        "                synonyms.add(lemma.name().lower().replace('_', ' '))\n",
        "    return word_set.union(synonyms)\n",
        "\n",
        "# Розширюємо наші лексикони\n",
        "# Увага: цей процес може додати шум, тому використовувати обережно.\n",
        "# positive_words_expanded = expand_with_synonyms(positive_words)\n",
        "# negative_words_expanded = expand_with_synonyms(negative_words)\n",
        "\n",
        "# print(f\"Кількість розширених позитивних слів: {len(positive_words_expanded)}\")\n",
        "# print(f\"Кількість розширених негативних слів: {len(negative_words_expanded)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Адаптація функції count_tweets\n",
        "def build_freqs(positive_words, negative_words):\n",
        "    freqs = {}\n",
        "    # Мітка 1.0 для позитивних, 0.0 для негативних\n",
        "    for word in positive_words:\n",
        "        freqs[(word, 1.0)] = 1\n",
        "    for word in negative_words:\n",
        "        freqs[(word, 0.0)] = 1\n",
        "    return freqs\n",
        "\n",
        "freqs = build_freqs(positive_words, negative_words)"
      ],
      "metadata": {
        "id": "fJYayVMemLMR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_naive_bayes_from_lexicon(freqs, positive_words, negative_words):\n",
        "    loglikelihood = {}\n",
        "\n",
        "    # Встановлюємо logprior в 0, оскільки припускаємо P(pos) = P(neg)\n",
        "    # logprior = log(P(pos)/P(neg)) = log(1) = 0\n",
        "    logprior = 0.0\n",
        "\n",
        "    # Створюємо словник унікальних слів\n",
        "    vocab = set([key[0] for key in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # N_pos та N_neg - загальна кількість слів у кожному класі\n",
        "    # Оскільки ми присвоїли частоту 1 кожному слову, це просто розмір списків\n",
        "    N_pos = len(positive_words)\n",
        "    N_neg = len(negative_words)\n",
        "\n",
        "    # Розрахунок loglikelihood для кожного слова\n",
        "    for word in vocab:\n",
        "        # Частота слова у позитивному та негативному класах\n",
        "        freq_pos = freqs.get((word, 1.0), 0)\n",
        "        freq_neg = freqs.get((word, 0.0), 0)\n",
        "\n",
        "        # Ймовірність слова для кожного класу зі згладжуванням Лапласа\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    return logprior, loglikelihood\n",
        "\n",
        "logprior, loglikelihood = train_naive_bayes_from_lexicon(freqs, positive_words, negative_words)"
      ],
      "metadata": {
        "id": "P0ml1ZPwmNji"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "import string\n",
        "\n",
        "def process_text(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    text = re.sub(r'#', '', text) # Видалення хештегів\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    clean_tokens = []\n",
        "    for word in tokens:\n",
        "        word = word.lower()\n",
        "        if (word not in stopwords_english and\n",
        "            word not in string.punctuation):\n",
        "            stem_word = stemmer.stem(word)\n",
        "            clean_tokens.append(stem_word)\n",
        "    return clean_tokens\n",
        "\n",
        "def naive_bayes_predict(text, logprior, loglikelihood):\n",
        "    processed_text = process_text(text)\n",
        "    p = logprior\n",
        "\n",
        "    for word in processed_text:\n",
        "        if word in loglikelihood:\n",
        "            p += loglikelihood[word]\n",
        "\n",
        "    return p\n",
        "\n",
        "# Тестування на прикладі\n",
        "my_sentence = \"This movie was not good, it was actually very bad and boring.\"\n",
        "prediction = naive_bayes_predict(my_sentence, logprior, loglikelihood)\n",
        "print(f\"Показник тональності: {prediction}\")\n",
        "print(f\"Прогнозована тональність: {'Позитивна' if prediction > 0 else 'Негативна'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCF8BOZPmPw8",
        "outputId": "e0ad07d3-a1b2-4563-b924-9138ddf4c4a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Показник тональності: 0.13031348927634978\n",
            "Прогнозована тональність: Позитивна\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення власного тестового набору\n",
        "test_x = [\n",
        "    'I am happy because I am learning.',\n",
        "    'This is a wonderful experience.',\n",
        "    'I feel sad and tired.',\n",
        "    'This was a terrible movie.',\n",
        "    'The service was acceptable.',\n",
        "    'I am not happy with the result.',\n",
        "    'The book is amazing and fantastic.'\n",
        "]\n",
        "# Мітки: 1 для позитивних, 0 для негативних\n",
        "test_y = np.array([1, 1, 0, 0, 1, 0, 1])\n",
        "\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    y_hats = []\n",
        "    for text in test_x:\n",
        "        if naive_bayes_predict(text, logprior, loglikelihood) > 0:\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            y_hat_i = 0\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    y_hats = np.array(y_hats)\n",
        "    accuracy = np.mean(y_hats == test_y)\n",
        "    return accuracy\n",
        "\n",
        "accuracy = test_naive_bayes(test_x, test_y, logprior, loglikelihood)\n",
        "print(f\"Точність класифікатора на власному тестовому наборі: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnEAvFidmR3a",
        "outputId": "4767f003-f2fb-4a9c-ebc7-efbad6f0f302"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точність класифікатора на власному тестовому наборі: 0.5714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_loglikelihood = sorted(loglikelihood.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Топ-10 найбільш позитивних слів:\")\n",
        "for word, value in sorted_loglikelihood[:10]:\n",
        "    print(f\"{word}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nТоп-10 найбільш негативних слів:\")\n",
        "for word, value in sorted_loglikelihood[-10:]:\n",
        "    print(f\"{word}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj0Dfy5KmjbJ",
        "outputId": "4c0652ee-0a33-4c84-c9e2-2d60f54dbf64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 найбільш позитивних слів:\n",
            "upliftment: 0.9676\n",
            "captivating: 0.9676\n",
            "endorsement: 0.9676\n",
            "rock-star: 0.9676\n",
            "exquisite: 0.9676\n",
            "enjoyably: 0.9676\n",
            "distinction: 0.9676\n",
            "complimentary: 0.9676\n",
            "rightness: 0.9676\n",
            "cheerful: 0.9676\n",
            "\n",
            "Топ-10 найбільш негативних слів:\n",
            "blatantly: -0.4187\n",
            "alarmingly: -0.4187\n",
            "misinterpret: -0.4187\n",
            "scratch: -0.4187\n",
            "vague: -0.4187\n",
            "culpable: -0.4187\n",
            "anomalous: -0.4187\n",
            "sinking: -0.4187\n",
            "diabolical: -0.4187\n",
            "intimidate: -0.4187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Аналіз помилок:')\n",
        "print('Справжня | Прогноз  | Текст')\n",
        "print('------------------------------------')\n",
        "for x, y in zip(test_x, test_y):\n",
        "    prediction = naive_bayes_predict(x, logprior, loglikelihood)\n",
        "    y_hat = 1 if prediction > 0 else 0\n",
        "    if y != y_hat:\n",
        "        print(f\"   {y}    |    {y_hat}     | {x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On4_9IuKmtcB",
        "outputId": "86650fe9-a02c-48a7-b799-9f64ebbbc8c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аналіз помилок:\n",
            "Справжня | Прогноз  | Текст\n",
            "------------------------------------\n",
            "   1    |    0     | I am happy because I am learning.\n",
            "   1    |    0     | The service was acceptable.\n",
            "   1    |    0     | The book is amazing and fantastic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data_to_save = {\n",
        "    'logprior': logprior,\n",
        "    'loglikelihood': loglikelihood\n",
        "}\n",
        "\n",
        "with open('naive_bayes_model.json', 'w') as f:\n",
        "    json.dump(data_to_save, f)"
      ],
      "metadata": {
        "id": "0kfcA2n4m0iC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PkOgL_enHiF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}